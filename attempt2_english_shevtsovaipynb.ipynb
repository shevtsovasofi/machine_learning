{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsFahygpJWNgjSfGGs9P69",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shevtsovasofi/machine_learning/blob/main/attempt2_english_shevtsovaipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание\n",
        "\n",
        "Генерация текста на основе небольшого датасета\n",
        "\n",
        "- Предварительный анализ: чистка текста\n",
        "- Обучение модели. Используйте образец из туториала по RNNи\n",
        "- Генерация текста. Используйте образец из туториала по RNN\n",
        "- Сгенерируйте несколько текстов с помощью созданной модели"
      ],
      "metadata": {
        "id": "G4IsaaIcOghs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import requests\n",
        "import re"
      ],
      "metadata": {
        "id": "ztHHpmE0nhEy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.gutenberg.org/files/11/11-0.txt\"  #я взяла текст \"Алисы в стране чудев\" из проекта Гутенберг\n",
        "data = requests.get(url).text"
      ],
      "metadata": {
        "id": "oREE1H9PniBd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.lower()\n",
        "data = re.sub(r'[^a-z\\s\\.]', '', data)  # Оставим точки для разделения\n",
        "data = re.sub(r'\\s+', ' ', data)"
      ],
      "metadata": {
        "id": "8R5EMJPNr8uJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = data.split('.') #разделяем на предложения"
      ],
      "metadata": {
        "id": "Pw2jQCdK3EYt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [s.strip() for s in sentences if s.strip() != '']\n",
        "\n",
        "for i, s in enumerate(sentences[:50]):\n",
        "    print(f\"{i+1}: {s}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_54vseOW3ID_",
        "outputId": "c7e4137c-6a5e-4da7-9db1-e6a2b1baeaea"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: start of the project gutenberg ebook illustration alices adventures in wonderland by lewis carroll the millennium fulcrum edition\n",
            "2: contents chapter i\n",
            "3: down the rabbithole chapter ii\n",
            "4: the pool of tears chapter iii\n",
            "5: a caucusrace and a long tale chapter iv\n",
            "6: the rabbit sends in a little bill chapter v\n",
            "7: advice from a caterpillar chapter vi\n",
            "8: pig and pepper chapter vii\n",
            "9: a mad teaparty chapter viii\n",
            "10: the queens croquetground chapter ix\n",
            "11: the mock turtles story chapter x\n",
            "12: the lobster quadrille chapter xi\n",
            "13: who stole the tarts chapter xii\n",
            "14: alices evidence chapter i\n",
            "15: down the rabbithole alice was beginning to get very tired of sitting by her sister on the bank and of having nothing to do once or twice she had peeped into the book her sister was reading but it had no pictures or conversations in it and what is the use of a book thought alice without pictures or conversations so she was considering in her own mind as well as she could for the hot day made her feel very sleepy and stupid whether the pleasure of making a daisychain would be worth the trouble of getting up and picking the daisies when suddenly a white rabbit with pink eyes ran close by her\n",
            "16: there was nothing so very remarkable in that nor did alice think it so very much out of the way to hear the rabbit say to itself oh dear oh dear i shall be late when she thought it over afterwards it occurred to her that she ought to have wondered at this but at the time it all seemed quite natural but when the rabbit actually took a watch out of its waistcoatpocket and looked at it and then hurried on alice started to her feet for it flashed across her mind that she had never before seen a rabbit with either a waistcoatpocket or a watch to take out of it and burning with curiosity she ran across the field after it and fortunately was just in time to see it pop down a large rabbithole under the hedge\n",
            "17: in another moment down went alice after it never once considering how in the world she was to get out again\n",
            "18: the rabbithole went straight on like a tunnel for some way and then dipped suddenly down so suddenly that alice had not a moment to think about stopping herself before she found herself falling down a very deep well\n",
            "19: either the well was very deep or she fell very slowly for she had plenty of time as she went down to look about her and to wonder what was going to happen next\n",
            "20: first she tried to look down and make out what she was coming to but it was too dark to see anything then she looked at the sides of the well and noticed that they were filled with cupboards and bookshelves here and there she saw maps and pictures hung upon pegs\n",
            "21: she took down a jar from one of the shelves as she passed it was labelled orange marmalade but to her great disappointment it was empty she did not like to drop the jar for fear of killing somebody underneath so managed to put it into one of the cupboards as she fell past it\n",
            "22: well thought alice to herself after such a fall as this i shall think nothing of tumbling down stairs how brave theyll all think me at home why i wouldnt say anything about it even if i fell off the top of the house which was very likely true\n",
            "23: down down down\n",
            "24: would the fall never come to an end i wonder how many miles ive fallen by this time she said aloud\n",
            "25: i must be getting somewhere near the centre of the earth\n",
            "26: let me see that would be four thousand miles down i think for you see alice had learnt several things of this sort in her lessons in the schoolroom and though this was not a very good opportunity for showing off her knowledge as there was no one to listen to her still it was good practice to say it over yes thats about the right distancebut then i wonder what latitude or longitude ive got to alice had no idea what latitude was or longitude either but thought they were nice grand words to say\n",
            "27: presently she began again\n",
            "28: i wonder if i shall fall right through the earth how funny itll seem to come out among the people that walk with their heads downward the antipathies i think she was rather glad there was no one listening this time as it didnt sound at all the right word but i shall have to ask them what the name of the country is you know\n",
            "29: please maam is this new zealand or australia and she tried to curtsey as she spokefancy curtseying as youre falling through the air do you think you could manage it and what an ignorant little girl shell think me for asking no itll never do to ask perhaps i shall see it written up somewhere\n",
            "30: down down down\n",
            "31: there was nothing else to do so alice soon began talking again\n",
            "32: dinahll miss me very much tonight i should think dinah was the cat\n",
            "33: i hope theyll remember her saucer of milk at teatime\n",
            "34: dinah my dear i wish you were down here with me there are no mice in the air im afraid but you might catch a bat and thats very like a mouse you know\n",
            "35: but do cats eat bats i wonder and here alice began to get rather sleepy and went on saying to herself in a dreamy sort of way do cats eat bats do cats eat bats and sometimes do bats eat cats for you see as she couldnt answer either question it didnt much matter which way she put it\n",
            "36: she felt that she was dozing off and had just begun to dream that she was walking hand in hand with dinah and saying to her very earnestly now dinah tell me the truth did you ever eat a bat when suddenly thump thump down she came upon a heap of sticks and dry leaves and the fall was over\n",
            "37: alice was not a bit hurt and she jumped up on to her feet in a moment she looked up but it was all dark overhead before her was another long passage and the white rabbit was still in sight hurrying down it\n",
            "38: there was not a moment to be lost away went alice like the wind and was just in time to hear it say as it turned a corner oh my ears and whiskers how late its getting she was close behind it when she turned the corner but the rabbit was no longer to be seen she found herself in a long low hall which was lit up by a row of lamps hanging from the roof\n",
            "39: there were doors all round the hall but they were all locked and when alice had been all the way down one side and up the other trying every door she walked sadly down the middle wondering how she was ever to get out again\n",
            "40: suddenly she came upon a little threelegged table all made of solid glass there was nothing on it except a tiny golden key and alices first thought was that it might belong to one of the doors of the hall but alas either the locks were too large or the key was too small but at any rate it would not open any of them\n",
            "41: however on the second time round she came upon a low curtain she had not noticed before and behind it was a little door about fifteen inches high she tried the little golden key in the lock and to her great delight it fitted alice opened the door and found that it led into a small passage not much larger than a rathole she knelt down and looked along the passage into the loveliest garden you ever saw\n",
            "42: how she longed to get out of that dark hall and wander about among those beds of bright flowers and those cool fountains but she could not even get her head through the doorway and even if my head would go through thought poor alice it would be of very little use without my shoulders\n",
            "43: oh how i wish i could shut up like a telescope i think i could if i only knew how to begin\n",
            "44: for you see so many outoftheway things had happened lately that alice had begun to think that very few things indeed were really impossible\n",
            "45: there seemed to be no use in waiting by the little door so she went back to the table half hoping she might find another key on it or at any rate a book of rules for shutting people up like telescopes this time she found a little bottle on it which certainly was not here before said alice and round the neck of the bottle was a paper label with the words drink me beautifully printed on it in large letters\n",
            "46: it was all very well to say drink me but the wise little alice was not going to do that in a hurry\n",
            "47: no ill look first she said and see whether its marked poison or not for she had read several nice little histories about children who had got burnt and eaten up by wild beasts and other unpleasant things all because they would not remember the simple rules their friends had taught them such as that a redhot poker will burn you if you hold it too long and that if you cut your finger very deeply with a knife it usually bleeds and she had never forgotten that if you drink much from a bottle marked poison it is almost certain to disagree with you sooner or later\n",
            "48: however this bottle was not marked poison so alice ventured to taste it and finding it very nice it had in fact a sort of mixed flavour of cherrytart custard pineapple roast turkey toffee and hot buttered toast she very soon finished it off\n",
            "49: what a curious feeling said alice i must be shutting up like a telescope\n",
            "50: and so it was indeed she was now only ten inches high and her face brightened up at the thought that she was now the right size for going through the little door into that lovely garden\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data= sentences[15:8000]\n",
        "'''\n",
        "сначала я обучала на начале датасета с самой первой строчке, и он замусорился названиями глав и римскими цифрами,\n",
        "которые сстабильно всплывали в генерируемых предложениях. поэтому я убрала первые 15 строк\n",
        "'''"
      ],
      "metadata": {
        "id": "b96GwCAEu1Ah"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализируем токенизатор\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Обучаем токенизатор на заголовках\n",
        "tokenizer.fit_on_texts(data)\n",
        "\n",
        "# Преобразуем заголовки в последовательности чисел\n",
        "sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "# Создаем входные и выходные данные\n",
        "X = []\n",
        "y = []\n",
        "for seq in sequences:\n",
        "    for i in range(1, len(seq)):\n",
        "        X.append(seq[:i])\n",
        "        y.append(seq[i])\n"
      ],
      "metadata": {
        "id": "vh6DdhFJsu4x"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:10], y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP_k-2Dysw8v",
        "outputId": "d3a76fdc-345d-4890-c062-7807ae662ba8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[56],\n",
              "  [56, 13],\n",
              "  [56, 13, 130],\n",
              "  [56, 13, 130, 24],\n",
              "  [56, 13, 130, 24, 27],\n",
              "  [56, 13, 130, 24, 27, 1051],\n",
              "  [56, 13, 130, 24, 27, 1051, 11],\n",
              "  [56, 13, 130, 24, 27, 1051, 11, 14],\n",
              "  [56, 13, 130, 24, 27, 1051, 11, 14, 825],\n",
              "  [56, 13, 130, 24, 27, 1051, 11, 14, 825, 66]],\n",
              " [13, 130, 24, 27, 1051, 11, 14, 825, 66, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразуем списки в массивы numpy\n",
        "X = np.asarray(X, dtype=\"object\")\n",
        "y = np.array(y)\n",
        "\n",
        "# Дополняем последовательности до одинаковой длины\n",
        "X = pad_sequences(X)\n",
        "\n",
        "# Преобразуем y в one-hot encoding\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=len(tokenizer.word_index) + 1)"
      ],
      "metadata": {
        "id": "L8dewBOms3iS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем модель\n",
        "model = Sequential()\n",
        "\n",
        "# Добавляем слой Embedding\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=X.shape[1]))\n",
        "\n",
        "# Добавляем слой LSTM\n",
        "model.add(LSTM(150, return_sequences=False))\n",
        "\n",
        "# Добавляем полносвязный слой\n",
        "model.add(Dense(len(tokenizer.word_index) + 1, activation='softmax'))\n",
        "\n",
        "# Компилируем модель\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Выводим информацию о модели\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "MJalI__Jt9Kl",
        "outputId": "be9dda32-6c05-47f4-df35-460b7a7679fc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, y, epochs=50, batch_size=64, validation_split=0.2) #это самые хорошие результаты, которых удалось достичь..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p1KZHvFuDD7",
        "outputId": "6f8cb1c9-413e-42da-ad55-d3c67685178e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.0473 - loss: 6.5940 - val_accuracy: 0.0852 - val_loss: 6.1841\n",
            "Epoch 2/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.0560 - loss: 5.9215 - val_accuracy: 0.0994 - val_loss: 6.1579\n",
            "Epoch 3/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.0724 - loss: 5.7071 - val_accuracy: 0.0979 - val_loss: 6.0203\n",
            "Epoch 4/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.0979 - loss: 5.4128 - val_accuracy: 0.1163 - val_loss: 5.9538\n",
            "Epoch 5/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.1183 - loss: 5.1794 - val_accuracy: 0.1232 - val_loss: 5.9178\n",
            "Epoch 6/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.1319 - loss: 4.9576 - val_accuracy: 0.1289 - val_loss: 5.8958\n",
            "Epoch 7/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.1499 - loss: 4.7445 - val_accuracy: 0.1289 - val_loss: 5.8883\n",
            "Epoch 8/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.1675 - loss: 4.5771 - val_accuracy: 0.1340 - val_loss: 5.9160\n",
            "Epoch 9/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.1741 - loss: 4.4612 - val_accuracy: 0.1402 - val_loss: 5.9379\n",
            "Epoch 10/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.1859 - loss: 4.2960 - val_accuracy: 0.1327 - val_loss: 5.9761\n",
            "Epoch 11/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.1935 - loss: 4.1687 - val_accuracy: 0.1400 - val_loss: 6.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.2056 - loss: 4.0190 - val_accuracy: 0.1412 - val_loss: 6.0456\n",
            "Epoch 13/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.2126 - loss: 3.9152 - val_accuracy: 0.1425 - val_loss: 6.0916\n",
            "Epoch 14/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.2292 - loss: 3.7731 - val_accuracy: 0.1423 - val_loss: 6.1579\n",
            "Epoch 15/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.2351 - loss: 3.6550 - val_accuracy: 0.1449 - val_loss: 6.1933\n",
            "Epoch 16/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.2521 - loss: 3.5314 - val_accuracy: 0.1455 - val_loss: 6.2502\n",
            "Epoch 17/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.2646 - loss: 3.4307 - val_accuracy: 0.1406 - val_loss: 6.3094\n",
            "Epoch 18/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.2870 - loss: 3.2978 - val_accuracy: 0.1467 - val_loss: 6.3612\n",
            "Epoch 19/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.3029 - loss: 3.1909 - val_accuracy: 0.1406 - val_loss: 6.4145\n",
            "Epoch 20/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3265 - loss: 3.0880 - val_accuracy: 0.1414 - val_loss: 6.4920\n",
            "Epoch 21/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3373 - loss: 2.9847 - val_accuracy: 0.1435 - val_loss: 6.5501\n",
            "Epoch 22/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3628 - loss: 2.8742 - val_accuracy: 0.1410 - val_loss: 6.6155\n",
            "Epoch 23/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.3769 - loss: 2.7776 - val_accuracy: 0.1416 - val_loss: 6.6988\n",
            "Epoch 24/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3919 - loss: 2.7014 - val_accuracy: 0.1388 - val_loss: 6.7492\n",
            "Epoch 25/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4134 - loss: 2.6074 - val_accuracy: 0.1412 - val_loss: 6.8136\n",
            "Epoch 26/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4327 - loss: 2.5164 - val_accuracy: 0.1346 - val_loss: 6.8881\n",
            "Epoch 27/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.4484 - loss: 2.4344 - val_accuracy: 0.1364 - val_loss: 6.9657\n",
            "Epoch 28/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4658 - loss: 2.3414 - val_accuracy: 0.1344 - val_loss: 7.0299\n",
            "Epoch 29/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4729 - loss: 2.2958 - val_accuracy: 0.1340 - val_loss: 7.1221\n",
            "Epoch 30/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.4961 - loss: 2.1932 - val_accuracy: 0.1346 - val_loss: 7.1767\n",
            "Epoch 31/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.5148 - loss: 2.1277 - val_accuracy: 0.1358 - val_loss: 7.2613\n",
            "Epoch 32/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.5157 - loss: 2.0982 - val_accuracy: 0.1331 - val_loss: 7.3393\n",
            "Epoch 33/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.5333 - loss: 2.0255 - val_accuracy: 0.1283 - val_loss: 7.4141\n",
            "Epoch 34/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.5575 - loss: 1.9384 - val_accuracy: 0.1303 - val_loss: 7.4840\n",
            "Epoch 35/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.5675 - loss: 1.8842 - val_accuracy: 0.1281 - val_loss: 7.5585\n",
            "Epoch 36/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.5795 - loss: 1.8227 - val_accuracy: 0.1265 - val_loss: 7.6413\n",
            "Epoch 37/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.5995 - loss: 1.7495 - val_accuracy: 0.1313 - val_loss: 7.6967\n",
            "Epoch 38/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.6043 - loss: 1.7170 - val_accuracy: 0.1246 - val_loss: 7.7754\n",
            "Epoch 39/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.6266 - loss: 1.6616 - val_accuracy: 0.1273 - val_loss: 7.8444\n",
            "Epoch 40/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.6331 - loss: 1.6054 - val_accuracy: 0.1228 - val_loss: 7.9456\n",
            "Epoch 41/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.6466 - loss: 1.5638 - val_accuracy: 0.1303 - val_loss: 7.9951\n",
            "Epoch 42/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.6580 - loss: 1.4951 - val_accuracy: 0.1236 - val_loss: 8.0848\n",
            "Epoch 43/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.6708 - loss: 1.4523 - val_accuracy: 0.1228 - val_loss: 8.1619\n",
            "Epoch 44/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.6806 - loss: 1.4059 - val_accuracy: 0.1204 - val_loss: 8.2104\n",
            "Epoch 45/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.6907 - loss: 1.3712 - val_accuracy: 0.1250 - val_loss: 8.2888\n",
            "Epoch 46/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7082 - loss: 1.3050 - val_accuracy: 0.1285 - val_loss: 8.3543\n",
            "Epoch 47/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7113 - loss: 1.2707 - val_accuracy: 0.1234 - val_loss: 8.4262\n",
            "Epoch 48/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.7224 - loss: 1.2377 - val_accuracy: 0.1236 - val_loss: 8.5097\n",
            "Epoch 49/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.7321 - loss: 1.1976 - val_accuracy: 0.1174 - val_loss: 8.5768\n",
            "Epoch 50/50\n",
            "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.7392 - loss: 1.1805 - val_accuracy: 0.1164 - val_loss: 8.6456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "RzO7ZuHs5vfH",
        "outputId": "780cd55a-707b-4e79-d09c-5fb2c53cced7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m298\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m274,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │         \u001b[38;5;34m150,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2747\u001b[0m)                │         \u001b[38;5;34m414,797\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">274,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2747</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">414,797</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,520,293\u001b[0m (9.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,520,293</span> (9.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m840,097\u001b[0m (3.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">840,097</span> (3.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,680,196\u001b[0m (6.41 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,680,196</span> (6.41 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для генерации текста\n",
        "def generate_text(seed_text, next_words, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text"
      ],
      "metadata": {
        "id": "2A-uoSwC53rX"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерируем новый текст\n",
        "generated_text = generate_text(\"cat said\", 20, X.shape[1])\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WsnRS_C59WS",
        "outputId": "619ce447-3926-4097-d095-3a62fe8083b9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "cat said the cat and vanished again in a low voice to the company generally you are all pardoned such a tiny\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вывод:  loss большой, но на примерах сгенерированного текста видно, на чем модель обучалась, также соблюдается какая-то грамматическая структура."
      ],
      "metadata": {
        "id": "SHmpjmSDNlZP"
      }
    }
  ]
}